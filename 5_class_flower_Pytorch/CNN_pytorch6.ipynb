{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from operator import itemgetter\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "import random as rn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def accuracy(loader, model):\n",
    "    \"\"\"Calculate the accuracy of a given model on a given loader\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64,128,5)\n",
    "        self.conv4 = nn.Conv2d(128,128,5)\n",
    "        self.fc1 = nn.Linear(5*5*128, 120)\n",
    "        # self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(120, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = 'archive/flowers'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = ImageFolder(path, transform=transform.Compose([\n",
    "                                 transform.Resize((150, 150)),\n",
    "                                 transform.ToTensor(),\n",
    "                                 transform.Normalize((0.4124234616756439, 0.3674212694168091, 0.2578217089176178),\n",
    "                                                     (0.3268945515155792, 0.29282665252685547, 0.29053378105163574))]))\n",
    "invTrans = transform.Compose([ transform.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.3268945515155792, 1/0.29282665252685547, 1/0.29053378105163574 ]),\n",
    "                                transform.Normalize(mean = [ -0.4124234616756439, -0.3674212694168091, -0.2578217089176178 ],\n",
    "                                                     std = [ 1., 1., 1. ])])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 120\n",
    "seed = 42\n",
    "train, test = train_test_split(data, test_size=0.2, shuffle=True, random_state=seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aug1 = transform.Compose([transform.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                          transform.RandomRotation(5),\n",
    "                          transform.RandomAffine(degrees=11, translate=(0.1,0.1), scale=(0.8,0.8))])\n",
    "aug2 = transform.Compose([transform.RandomHorizontalFlip(),\n",
    "                         transform.RandomRotation(10),\n",
    "                         transform.RandomAffine(translate=(0.05,0.05), degrees=0),\n",
    "                         transform.RandomErasing(inplace=True, scale=(0.01, 0.23))])\n",
    "aug3 = transform.Compose([transform.RandomHorizontalFlip(p=0.5),\n",
    "                          transform.RandomRotation(15),\n",
    "                          transform.RandomAffine(translate=(0.08,0.1), degrees=15)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aug_train = aug2(aug1(train))\n",
    "big_train = ConcatDataset([train, aug_train])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(big_train, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('Daisy', 'Dandelion', 'Rose', 'Sunflower', 'Tulip')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(2,3)\n",
    "fig.set_size_inches(15,10)\n",
    "img,y = iter(trainloader).next()\n",
    "img = invTrans(img)\n",
    "for i in range(2):\n",
    "    for j in range (3):\n",
    "        l=rn.randint(0,31)\n",
    "        # label = list(train_dataset.class_indices.keys())[np.argmax(y[l])]\n",
    "        npimg = img[l].numpy()\n",
    "        ax[i,j].imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        ax[i,j].set_title(classes[y[l]])\n",
    "\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = Net()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "epochs = 8\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # print(i)\n",
    "        if i % 15 == 14:    # print every mini-batches\n",
    "            print(f'[Epoch: {epoch + 1}, {i + 1:5d}] loss: {running_loss / 15:.3f}')\n",
    "            running_loss = 0.0\n",
    "    train_acc.append(accuracy(trainloader, net))\n",
    "    test_acc.append(accuracy(testloader, net))\n",
    "print('Finished Training')\n",
    "plt.figure(figsize=(4, 8))\n",
    "# plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1,epochs+1), train_acc, label='Training Accuracy')\n",
    "plt.plot(range(1,epochs+1), test_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0,1.0)\n",
    "plt.xlim(0,epochs+1)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 8))\n",
    "plt.plot(range(1,epochs+1), train_acc, label='Training Accuracy')\n",
    "plt.plot(range(1,epochs+1), test_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0.4,1.0)\n",
    "plt.xlim(1,epochs+1)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PATH = './flower_sgd_10ep_3cn3l.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# dataiter = iter(testloader)\n",
    "# images, y = dataiter.next()\n",
    "fig,ax=plt.subplots(2,3)\n",
    "fig.set_size_inches(15,10)\n",
    "img,y = iter(testloader).next()\n",
    "outputs = net(img)\n",
    "_, pred= torch.max(outputs, 1)\n",
    "img = invTrans(img)\n",
    "for i in range(2):\n",
    "    for j in range (3):\n",
    "        l=rn.randint(0,31)\n",
    "        # label = list(train_dataset.class_indices.keys())[np.argmax(y[l])]\n",
    "        npimg = img[l].numpy()\n",
    "        ax[i,j].imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        if y[l] == pred[l]:\n",
    "            ax[i,j].set_title('Actual: '+classes[y[l]]+'  Predicted: '+classes[pred[l]], color = 'green')\n",
    "        else:\n",
    "            ax[i,j].set_title('Actual: '+classes[y[l]]+'  Predicted: '+classes[pred[l]], color = 'red')\n",
    "\n",
    "plt.tight_layout()\n",
    "# print images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on test images: {100 * correct // total} %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on train images: {100 * correct // total} %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy(testloader,net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}